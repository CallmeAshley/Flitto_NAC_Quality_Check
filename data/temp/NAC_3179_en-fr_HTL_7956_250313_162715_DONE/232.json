{
    "source": "en_US",
    "target": "fr_FR",
    "text": "For self-supervised speaker verification, the quality of pseudo labels decides the upper bound of the system due to the massive unreliable labels. In this work, we propose dynamic loss-gate and label correction (DLG-LC) to alleviate the performance degradation caused by unreliable estimated labels. In DLG, we adopt Gaussian Mixture Model (GMM) to dynamically model the loss distribution and use the estimated GMM to distinguish the reliable and unreliable labels automatically. Besides, to better utilize the unreliable data instead of dropping them directly, we correct the unreliable label with model predictions. Moreover, we apply the negative-pairs-free DINO framework in our experiments for further improvement. Compared to the best-known speaker verification system with self-supervised learning, our proposed DLG-LC converges faster and achieves 11.45%, 18.35% and 15.16% relative improvement on Vox-O, Vox-E and Vox-H trials of Voxceleb1 evaluation dataset.",
    "trans": "Pour la vérification de locuteur en auto-supervision, la qualité des pseudo-étiquettes détermine la limite supérieure du système en raison du grand nombre d’étiquettes non fiables. Dans ce travail, nous proposons une méthode de filtrage dynamique des pertes et correction des étiquettes (DLG-LC) afin d’atténuer la dégradation des performances causée par ces étiquettes estimées non fiables. Dans DLG, nous utilisons un modèle de mélange gaussien (GMM) pour modéliser dynamiquement la distribution des pertes et exploitons le GMM estimé afin de distinguer automatiquement les étiquettes fiables et non fiables. Par ailleurs, plutôt que d’éliminer directement les données considérées comme non fiables, nous corrigeons les étiquettes erronées à l’aide des prédictions du modèle. En outre, nous appliquons le cadre DINO, qui ne repose pas sur des paires négatives, afin d’améliorer davantage les performances expérimentales. Comparé au meilleur système de vérification de locuteur basé sur l’apprentissage auto-supervisé connu à ce jour, notre méthode DLG-LC converge plus rapidement et offre une amélioration relative de 11,45 %, 18,35 % et 15,16 % sur les essais Vox-O, Vox-E et Vox-H du jeu de données d’évaluation VoxCeleb1."
}