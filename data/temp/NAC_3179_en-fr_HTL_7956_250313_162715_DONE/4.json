{
    "source": "en_US",
    "target": "fr_FR",
    "text": "DDPG-Based Parameter Adaptation Method for PSO Algorithm\n3.2.1. State Space\nThe state space, serving as the input for the Actor network, dictates the convergence\nrate of the algorithm. For conventional deep reinforcement learning methods, the state\nspace design should satisfy the following criteria:\n• The chosen states should have relevance to the task objective;\n• The chosen states should be as mutually independent as possible and encompass all\ntask indicators;\n• The chosen states should be capable of mapping to the same value range.\nSustainability 2023, 15, 12101 8 of 16\n2\n2\nDiv=\nAdhering to the aforementioned principles, the state space of the algorithm comprises\nthree elements: the evolutionary progress of the population, the population diversity, and\nthe present optimization capability of the population.\nThe iteration percentage in particle swarm optimization is a parameter that signifies the\nextent of algorithm execution. At the algorithm’s commencement, this iteration progress\nis at 0%, incrementally increasing until the algorithm’s completion, at which point it\nreaches 100%. The definition of the iteration percentage can be formulated using the\nfollowing equation:\nIter=",
    "trans": "Méthode d'Adaptation des Paramètres du PSO Basée sur DDPG\n3.2.1. Espace d'État\nL’espace d’état, servant d’entrée au réseau de l’Acteur, détermine le taux\nde convergence de l’algorithme. Pour les méthodes classiques d’apprentissage par renforcement profond, la conception de\nl’espace d’état doit respecter les critères suivants :\n• Les états sélectionnés doivent être pertinents par rapport à l’objectif de la tâche ;\n• Les états sélectionnés doivent être aussi indépendants que possible les uns des autres et couvrir\ntous les indicateurs de la tâche ;\n• Les états sélectionnés doivent être capables d’être mappés sur la même plage de valeurs.\nSustainability 2023, 15, 12101 8 of 16\n2\n2\nDiv=\nAdhérant à ces principes, l’espace d’état de l’algorithme se compose\nde trois éléments : le progrès évolutif de la population, la diversité de la population et\nla capacité d’optimisation actuelle de la population.\nLe pourcentage d’itération dans l’optimisation par essaims particulaires est un paramètre qui indique\nle degré d’exécution de l’algorithme. Au début de l’algorithme, cette progression d’itération est à\n0 % et augmente progressivement jusqu’à la fin de l’algorithme, où elle\natteint 100 %. La définition du pourcentage d’itération peut être formulée à l’aide\nde l’équation suivante :\nIter="
}