{
    "source": "en_US",
    "target": "ko_KR",
    "text": "Semantic Feature Injection: We employ the region classification model to produce semantically meaningful visual features of the current observation. Specifically, we extract features at different levels of the visual encoder of the region classifier, together with a CNN with transposed convolutional layers to upsample and align the spatial shape of the features to that of the output of the UNet encoders. At this point, two parallel pipelines follow the generation of the occupancy map and the region map. We use two different CNNs to merge the multi-modal features obtained from the RGB and depth encoders, and the CLIP features. The merge module that generates the occupancy map uses RGB and depth features, while the other merge module also includes the CLIP features. The output of the merge modules is fed to two UNet decoders to produce the final egocentric occupancy map and region map",
    "trans": "의미론적 특징 주입: 우리는 현재 관찰의 의미론적으로 뜻있는 시각적 특징을 생성하기 위해 지역 분류 모델을 사용합니다. 구체적으로, 우리는 지역 분류기의 시각적 인코더의 다양한 수준에서 특징을 추출하고, 특징의 공간 형태를 UNet 인코더의 출력 형태에 맞춰 업샘플링하고 정렬하기 위해 전치된 합성곱 층을 가진 CNN과 함께 추출합니다. 이 시점에서 두 개의 병렬 파이프라인은 점유 지도와 지역 지도의 생성을 따릅니다. 우리는 두 개의 서로 다른 CNN을 사용하여 RGB 및 깊이 인코더에서 얻은 다중 모드 기능과 CLIP 기능을 병합합니다. 점유 맵을 생성하는 병합 모듈은 RGB 및 깊이 기능을 사용하는 반면 다른 병합 모듈에는 CLIP 기능도 포함되어 있습니다. 병합 모듈의 출력은 두 개의 UNet 디코더에 공급되어 최종 자기중심적 점유 지도와 지역 지도를 생성합니다."
}