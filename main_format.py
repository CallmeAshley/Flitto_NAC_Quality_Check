import os
import json
import random
from glob import glob
from collections import defaultdict
from time import time

from utils.gpt_client import ask_gpt
from prompt_builder.prompt_cache import (
    build_category_messages,        # ì¹´í…Œê³ ë¦¬ ê°ì§€(ì ‘ë‘ì‚¬ ìºì‹œ)
    build_check_messages_cached,    # ê²€ìˆ˜(ì ‘ë‘ì‚¬ ìºì‹œ)
)

# =========================
# ê²½ë¡œ/ëª¨ë¸/ë‹¨ê°€ ì„¤ì •
# =========================
INPUT_DIR = "/mnt/c/Users/Flitto/Documents/NAC/LLMê²€ìˆ˜/Advanced/data/input2_json"
OUTPUT_DIR = "/mnt/c/Users/Flitto/Documents/NAC/LLMê²€ìˆ˜/Advanced/data/output2"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ì‚¬ìš© ëª¨ë¸ (ë¹„ìš© ê³„ì‚°/í† í° ê³„ì¸¡ì—ì„œ í™œìš©)
MODEL_NAME = "gpt-4o"  # ë˜ëŠ” "gpt-5"

# 1í† í° ë‹¨ê°€ (per-token)
RATES = {
    "gpt-4o": {"input": 0.00000250, "cached": 0.00000125,  "output": 0.00001000},
    "gpt-5":  {"input": 0.00000125, "cached": 0.000000125, "output": 0.00001000},
}

total_usage = defaultdict(int)  # ì „ì²´ í•©ì‚°

def process_file(filepath: str, parent_folder: str):
    with open(filepath, "r", encoding="utf-8") as f:
        data = json.load(f)

    source = data["source"]
    target = data["target"]     # íƒ€ê¹ƒ ë¡œì¼€ì¼ (ì˜ˆ: "ko-KR")
    text = data["text"]
    trans = data["trans"]

    source_sentences = text.splitlines()
    trans_sentences = trans.splitlines()
    checked_sentences = []
    checked_detail = []

    # íŒŒì¼ ë‹¨ìœ„ í† í° ëˆ„ì (ìºì‹œ/ë¹„ìºì‹œ/ì¶œë ¥ ë¶„ë¦¬)
    file_cached_prompt_tokens = 0
    file_non_cached_prompt_tokens = 0
    file_output_tokens = 0

    # Step: Format Check (ì¤„ ë‹¨ìœ„)
    for i, sentence in enumerate(trans_sentences):
        original_sentence = sentence.strip()

        # ëŒ€ì‘í•˜ëŠ” source ë¬¸ì¥ ì¶”ì¶œ (fallback í¬í•¨)
        if len(source_sentences) == len(trans_sentences):
            source_for_line = source_sentences[i].strip()
        else:
            source_for_line = text  # fallback: ì „ì²´ ì‚¬ìš©

        # ë¹ˆ ì¤„ì€ ê·¸ëŒ€ë¡œ ë³´ì¡´
        if not original_sentence:
            checked_sentences.append(sentence)
            checked_detail.append({
                "original": sentence,
                "revised": sentence,
                "violated": False,
                "categories": []
            })
            continue

        # 1) ì¹´í…Œê³ ë¦¬ ê°ì§€ (system ê³ ì • â†’ cached input)
        sys_msg, usr_msg, meta = build_category_messages(original_sentence, model=MODEL_NAME)
        categories, usage = ask_gpt([sys_msg, usr_msg], model=MODEL_NAME)

        file_cached_prompt_tokens     += meta["cached_input_tokens"]
        file_non_cached_prompt_tokens += meta["non_cached_input_tokens"]
        file_output_tokens            += usage.get("completion_tokens", 0)

        revised = original_sentence

        if not categories or categories == "error" or categories == []:
            checked_sentences.append(revised)
            checked_detail.append({
                "source_text": source_for_line,
                "original": sentence,
                "revised": revised,
                "violated": False,
                "categories": []
            })
            continue

        # 2) ì¹´í…Œê³ ë¦¬ë³„ í¬ë§· ê²€ìˆ˜ (guidelineì„ system ì ‘ë‘ì‚¬ë¡œ â†’ 76ê°œ ìºì‹œ í™œìš©)
        for category in categories:
            built = build_check_messages_cached(
                revised, source_for_line, target, category, model=MODEL_NAME
            )
            if not built:
                continue  # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ guideline ì—†ìœ¼ë©´ ìŠ¤í‚µ
            sys_msg2, usr_msg2, meta2 = built

            revised_result, usage = ask_gpt([sys_msg2, usr_msg2], model=MODEL_NAME)

            file_cached_prompt_tokens     += meta2["cached_input_tokens"]
            file_non_cached_prompt_tokens += meta2["non_cached_input_tokens"]
            file_output_tokens            += usage.get("completion_tokens", 0)

            if isinstance(revised_result, str) and revised_result != "error":
                revised = revised_result.strip()

        violated_flag = (original_sentence != revised)

        checked_sentences.append(revised)
        checked_detail.append({
            "source_text": source_for_line,
            "original": sentence,
            "revised": revised,
            "violated": violated_flag,
            "categories": categories
        })

    filename = os.path.basename(filepath)

    output_data = {
        "source": source,
        "target": target,
        "text": text,
        "original_trans": trans,
        "checked_trans": "\n".join(checked_sentences),
        "checked_sentences": checked_detail
    }

    os.makedirs(os.path.join(OUTPUT_DIR, parent_folder), exist_ok=True)
    output_path = os.path.join(OUTPUT_DIR, parent_folder, filename)
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… Processed: {parent_folder}/{filename}")

    # íŒŒì¼ ë¹„ìš© ê³„ì‚° (per 1k tokens í™˜ì‚°)
    rate = RATES[MODEL_NAME]
    file_input_cost = (file_non_cached_prompt_tokens / 1000.0) * rate["input"] \
                    + (file_cached_prompt_tokens     / 1000.0) * rate["cached"]
    file_output_cost = (file_output_tokens / 1000.0) * rate["output"]
    file_total_cost  = file_input_cost + file_output_cost

    return {
        "filename": filename,
        "cached_prompt_tokens": file_cached_prompt_tokens,
        "non_cached_prompt_tokens": file_non_cached_prompt_tokens,
        "completion_tokens": file_output_tokens,
        "input_cost_usd": round(file_input_cost, 6),
        "output_cost_usd": round(file_output_cost, 6),
        "total_cost_usd": round(file_total_cost, 6),
        # ë ˆê±°ì‹œ í˜¸í™˜/ì´í•©
        "total_tokens": file_cached_prompt_tokens + file_non_cached_prompt_tokens + file_output_tokens,
    }

if __name__ == "__main__":
    random.seed(111)
    ss = time()
    folders = glob(os.path.join(INPUT_DIR, "*"))

    folder_logs = {}  # í´ë”ë³„ ë¡œê·¸ íŒŒì¼ ì €ì¥ìš©

    for folder_path in folders:
        if not os.path.isdir(folder_path):
            continue

        folder_name = os.path.basename(folder_path)
        json_files = glob(os.path.join(folder_path, "*.json"))
        json_files = random.sample(json_files, min(50, len(json_files)))

        folder_usage_log = {}

        # í´ë” ë‹¨ìœ„ ëˆ„ì 
        folder_cached_prompt_tokens = 0
        folder_non_cached_prompt_tokens = 0
        folder_completion_tokens = 0

        for file_path in json_files:
            s_time = time()
            usage = process_file(file_path, folder_name)

            folder_usage_log[usage["filename"]] = usage

            # í´ë” ëˆ„ì 
            folder_cached_prompt_tokens     += usage["cached_prompt_tokens"]
            folder_non_cached_prompt_tokens += usage["non_cached_prompt_tokens"]
            folder_completion_tokens        += usage["completion_tokens"]

            # ì „ì²´ ëˆ„ì 
            total_usage["cached_prompt_tokens"]     += usage["cached_prompt_tokens"]
            total_usage["non_cached_prompt_tokens"] += usage["non_cached_prompt_tokens"]
            total_usage["completion_tokens"]        += usage["completion_tokens"]
            total_usage["total_tokens"]             += usage["total_tokens"]

            e_time = time()
            print(f"âŒ› í•˜ë‚˜ì˜ Payload ì²˜ë¦¬ ì‹œê°„: {e_time - s_time:.2f}s")
            print(f"ğŸ’µ {usage['filename']} ë¹„ìš©(USD): {usage['total_cost_usd']:.6f}\n")

        # í´ë” ë¹„ìš© ê³„ì‚°
        rate = RATES[MODEL_NAME]
        folder_input_cost = (folder_non_cached_prompt_tokens / 1000.0) * rate["input"] \
                          + (folder_cached_prompt_tokens     / 1000.0) * rate["cached"]
        folder_output_cost = (folder_completion_tokens / 1000.0) * rate["output"]
        folder_total_cost  = folder_input_cost + folder_output_cost

        folder_usage_log["_summary"] = {
            "cached_prompt_tokens": folder_cached_prompt_tokens,
            "non_cached_prompt_tokens": folder_non_cached_prompt_tokens,
            "completion_tokens": folder_completion_tokens,
            "input_cost_usd": round(folder_input_cost, 6),
            "output_cost_usd": round(folder_output_cost, 6),
            "total_cost_usd": round(folder_total_cost, 6),
            "total_tokens": folder_cached_prompt_tokens + folder_non_cached_prompt_tokens + folder_completion_tokens,
        }

        folder_output_path = os.path.join(OUTPUT_DIR, folder_name, "token_usage_log.json")
        os.makedirs(os.path.join(OUTPUT_DIR, folder_name), exist_ok=True)
        with open(folder_output_path, "w", encoding="utf-8") as f:
            json.dump(folder_usage_log, f, indent=2, ensure_ascii=False)

    # ì „ì²´ ë¹„ìš© ê³„ì‚°
    rate = RATES[MODEL_NAME]
    prompt_cost  = (total_usage["non_cached_prompt_tokens"] / 1000.0) * rate["input"] \
                 + (total_usage["cached_prompt_tokens"]     / 1000.0) * rate["cached"]
    completion_cost = (total_usage["completion_tokens"] / 1000.0) * rate["output"]
    total_cost = prompt_cost + completion_cost

    print(f"\nğŸ“Šì´ í† í° ì‚¬ìš©ëŸ‰: {total_usage['total_tokens']}")
    print(f"- Cached input tokens:     {total_usage['cached_prompt_tokens']}")
    print(f"- Non-cached input tokens: {total_usage['non_cached_prompt_tokens']}")
    print(f"- Output tokens:           {total_usage['completion_tokens']}")
    print(f"ğŸ’° ì´ ìš”ê¸ˆ(USD): {total_cost:.6f}")

    ee = time()
    print(f"ëª¨ë“  ì‹œìŠ¤í…œ ì‘ë™ ì‹œê°„: {ee - ss:.2f}s")
